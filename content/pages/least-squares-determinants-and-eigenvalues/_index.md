---
content_type: page
title: 'Unit II: Least Squares, Determinants and Eigenvalues'
uid: cf73d07a-c972-ab3c-450a-0f10d0be0664
---

« [Previous]({{< baseurl >}}/pages/ax-b-and-the-four-subspaces/exam-1) | [Next]({{< baseurl >}}/pages/least-squares-determinants-and-eigenvalues/orthogonal-vectors-and-subspaces) »

![Figure excerpted from 'Introduction to Linear Algebra' by G.S. Strang](BASEURL_PLACEHOLDER/resources/unit_2_wide)

A graph and its edge-node incidence matrix.

Each component of a vector in Rn indicates a distance along one of the coordinate axes. This practice of dissecting a vector into directional components is an important one. In particular, it leads to the "least squares" method of fitting curves to collections of data. This unit also introduces matrix _eigenvalues_ and _eigenvectors_. Many calculations become simpler when working with a basis of eigenvectors.

The _determinant_ of a matrix is a number characterizing that matrix. This value is useful for determining whether a matrix is singular, computing its inverse, and more.

Looking for something specific in this course? The [Resource Index]({{< baseurl >}}/pages/resource-index) compiles links to most course resources in a single page.

« [Previous]({{< baseurl >}}/pages/ax-b-and-the-four-subspaces/exam-1) | [Next]({{< baseurl >}}/pages/least-squares-determinants-and-eigenvalues/orthogonal-vectors-and-subspaces) »